# fMRI data ##################################################################

fmri:
  sub-01:
    - ./data/fmri/sub-01_ImageNetTraining_fmriprep_volume_native.h5
  sub-02:
    - ./data/fmri/sub-02_ImageNetTraining_fmriprep_volume_native.h5
  sub-03:
    - ./data/fmri/sub-03_ImageNetTraining_fmriprep_volume_native.h5

rois:
  # V1:  ROI_V1 = 1
  # V2:  ROI_V2 = 1
  # V3:  ROI_V3 = 1
  # V4:  ROI_hV4 = 1
  # LOC: ROI_LOC = 1
  # FFA: ROI_FFA = 1
  # PPA: ROI_PPA = 1
  # LVC: ROI_LVC = 1
  # HVC: ROI_HVC = 1
  VC:  ROI_VC = 1

# The number of voxels used in feature decoding
rois voxel num:
  # V1:  500
  # V2:  500
  # V3:  500
  # V4:  500
  # LOC: 500
  # FFA: 500
  # PPA: 500
  # LVC: 500
  # HVC: 500
  VC:  500

label key:
  stimulus_name

# DNN features ###############################################################

feature dir:
  - /home/nu/data/contents_shared/ImageNetTraining/derivatives/features

network:
  caffe/VGG19

layers:
  - conv1_1
  - conv1_2
  - conv2_1
  - conv2_2
  - conv3_1
  - conv3_2
  - conv3_3
  - conv3_4
  - conv4_1
  - conv4_2
  - conv4_3
  - conv4_4
  - conv5_1
  - conv5_2
  - conv5_3
  - conv5_4
  - fc6
  - fc7
  - fc8

# Feature decoding (cross validation) ########################################

feature decoder dir:
  ./data/feature_decoding_cv/ImageNetTraining/deeprecon_fmriprep_rep5_500voxel_allunits_fastl2lir_alpha100

decoded feature dir:
  ./data/feature_decoding_cv/ImageNetTraining/deeprecon_fmriprep_rep5_500voxel_allunits_fastl2lir_alpha100

# Cross-validation -----------------------------------------------------------

# Key used to split training and test samples for cross-validation (e.g., 'Run')
#
cv key: Run

# Values of the key splitting training and test samples in each cross-validation fold.
# If omitted, leave-one-out cross-validation will be performed based on values of `cv key`.
#
# cv folds:
#   - train: [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
#     test:  [1, 2, 3]
#   - train: [1, 2, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
#     test:  [4, 5, 6]
#   - train: [1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
#     test:  [7, 8, 9]
#   - train: [1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
#     test:  [10, 11, 12]
#   - train: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24]
#     test:  [13, 14, 15]
#   - train: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24]
#     test:  [16, 17, 18]
#   - train: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 24]
#     test:  [19, 20, 21]
#   - train: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]
#     test:  [22, 23, 24]

# Alternative notation
#
# cv folds:
#   - {train: [3, 4, 5, 6], test: [1]}
#   - {train: [1, 2, 5, 6], test: [3]}
#   - {train: [1, 2, 3, 4], test: [5]}

# In each CV fold, the training samples are removed if they have overlapping values of `cv exclusive key` with the test samples so that the training and test samples do not have overlapping values for `cv exclusive key`.
# Set `null` if not specified.
#
cv exclusive key: category_index

# Learning parameters --------------------------------------------------------
alpha: 100
chunk axis: 1

# Figure output --------------------------------------------------------------
decoding figure dir:
  ./data/figures/ImageNetTraining/feature_decoding_cv/deeprecon_fmriprep_rep5_500voxel_allunits_fastl2lir_alpha100

